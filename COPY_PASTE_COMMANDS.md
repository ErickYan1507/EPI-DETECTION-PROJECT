# üöÄ COMMANDES PR√äTES √Ä COPIER-COLLER

## OPTION 1: ULTRA-RAPIDE (RECOMMAND√â) - 20-30 min/epoch

### √âtape 1: Redimensionner dataset (2-3 minutes)
```powershell
python optimize_training_speed.py --resize --size 416 --dataset dataset
```

### √âtape 2: Entra√Æner avec optimisations
```powershell
python train.py --dataset dataset --epochs 50 --batch-size 48 --img-size 416
```

**R√©sultat:** ~17-25 heures pour 50 epochs (1 jour!)

---

## OPTION 2: RAPIDE SANS REDIMENSIONNER - 45-60 min/epoch

### Directement entra√Æner (pas de pr√©traitement)
```powershell
python train.py --dataset dataset --epochs 50 --batch-size 32 --img-size 416
```

**R√©sultat:** ~37-50 heures pour 50 epochs (2 jours)

---

## OPTION 3: SCRIPT AUTOMATIS√â (PowerShell)

### Tout en un
```powershell
.\quick_train_ultra_fast.ps1
```

Le script demande si redimensionner puis g√®re tout automatiquement.

---

## OPTION 4: APR√àS ENTRA√éNEMENT - Affinage haute r√©solution (optionnel)

Si vous voulez meilleure pr√©cision en 640√ó640:

```powershell
python train.py --dataset dataset --epochs 20 --batch-size 24 --img-size 640 --weights models/best.pt
```

**Note:** Transfer learning sur le mod√®le pr√©-entra√Æn√© (converge vite)

---

## TEST RAPIDE MOD√àLE

Apr√®s entra√Ænement:
```powershell
python test_api_detection.py --model models/best.pt
```

---

## AFFICHAGE GUIDE D'OPTIMISATION

Pour revoir les d√©tails:
```powershell
python optimize_training_speed.py --guide
```

---

## D√âPANNAGE

### OutOfMemory?
```powershell
# Le script auto-r√©duit, mais vous pouvez forcer batch 16:
python train.py --dataset dataset --epochs 50 --batch-size 16 --img-size 416
```

### V√©rifier GPU disponible:
```powershell
python -c "import torch; print(f'GPU: {torch.cuda.is_available()}, Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
```

### V√©rifier RAM disponible:
```powershell
python -c "import psutil; mem = psutil.virtual_memory(); print(f'Total: {mem.total/1e9:.1f}GB, Available: {mem.available/1e9:.1f}GB, Used: {mem.percent}%')"
```

---

## R√âSUM√â GAINS

| M√©trique | Avant | Apr√®s | Gain |
|----------|-------|-------|------|
| Temps/epoch | 3:00h | 20-30min | **85%** ‚ö° |
| 50 epochs | 150h | 17-25h | **85%** ‚ö° |
| 100 epochs | 300h | 34-50h | **85%** ‚ö° |
| Jours | 12.5 | **1-2** | **10x plus rapide** üöÄ |

---

## FICHIERS CR√â√âS/MODIFI√âS

### Nouveaux fichiers:
- ‚úÖ `optimize_training_speed.py` - Script redimensionnement
- ‚úÖ `quick_train_ultra_fast.ps1` - Automation PowerShell
- ‚úÖ `quick_train_ultra_fast.sh` - Automation Bash
- ‚úÖ `SPEED_OPTIMIZATION_GUIDE.md` - Documentation d√©taill√©e
- ‚úÖ `OPTIMIZATION_APPLIED.txt` - Explications techniques
- ‚úÖ `START_OPTIMIZED_TRAINING.txt` - Commandes d√©taill√©es
- ‚úÖ `COPY_PASTE_COMMANDS.md` - Ce fichier

### Fichiers modifi√©s:
- üìù `train.py` - Param√®tres optimis√©s par d√©faut

---

## ‚è±Ô∏è ESTIMATIONS DE TEMPS

### Avec redimensionnement (Ultra-rapide):
```
Redimensionner: 2-3 min
50 epochs: 17-25 heures  
Total: ~17-26 heures (1 jour)
```

### Sans redimensionner (Rapide):
```
50 epochs: 37-50 heures
Total: ~37-50 heures (2 jours)
```

### Affinage 640√ó640 (optionnel):
```
20 epochs: 15-30 heures
Total: ~15-30 heures (1 jour)
```

---

## V√âRIFICATION PRE-LANCEMENT

Avant de lancer, copier-coller dans PowerShell:

```powershell
# V√©rifier GPU
python -c "import torch; print(f'GPU: {torch.cuda.is_available()}')"

# V√©rifier dataset
Get-ChildItem dataset/images/train | Measure-Object | Select-Object Count

# V√©rifier data.yaml
Test-Path dataset/data.yaml
```

Tous les verts? C'est parti! üöÄ

---

## üìö DOCUMENTATION COMPL√àTE

Pour plus de d√©tails:
- [SPEED_OPTIMIZATION_GUIDE.md](SPEED_OPTIMIZATION_GUIDE.md)
- [OPTIMIZATION_APPLIED.txt](OPTIMIZATION_APPLIED.txt)
- [START_OPTIMIZED_TRAINING.txt](START_OPTIMIZED_TRAINING.txt)

---

## üéØ COMMANDE D√âFINITIVE

```powershell
# ULTRA-RAPIDE (RECOMMAND√â):
python optimize_training_speed.py --resize --size 416 --dataset dataset; python train.py --dataset dataset --epochs 50 --batch-size 48 --img-size 416

# Ou split en deux:
python optimize_training_speed.py --resize --size 416 --dataset dataset
python train.py --dataset dataset --epochs 50 --batch-size 48 --img-size 416
```

√Ä vous de jouer! üöÄ‚ú®
