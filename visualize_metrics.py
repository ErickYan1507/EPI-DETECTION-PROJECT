#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VISUALISATION GRAPHIQUE - Performance du Mod√®le best.pt
"""

import json
import sys

# Charger les donn√©es
with open('model_metrics.json', 'r', encoding='utf-8') as f:
    metrics = json.load(f)

print("\n" + "="*80)
print("üìä VISUALISATION GRAPHIQUE - MOD√àLE BEST.PT")
print("="*80)

# --- Graphique 1: mAP par classe ---
print("\n1Ô∏è‚É£  mAP@0.5 PAR CLASSE")
print("-" * 80)

classes = {
    "Personne": metrics['class_metrics']['Personne']['mAP_0_5'],
    "Gilet": metrics['class_metrics']['Gilet']['mAP_0_5'],
    "Casque": metrics['class_metrics']['Casque']['mAP_0_5'],
    "Lunettes": metrics['class_metrics']['Lunettes']['mAP_0_5'],
    "Bottes": metrics['class_metrics']['Bottes']['mAP_0_5'],
}

max_width = 60
max_value = max(classes.values())

for class_name, value in sorted(classes.items(), key=lambda x: x[1], reverse=True):
    bar_width = int((value / max_value) * max_width)
    bar = "‚ñà" * bar_width + "‚ñë" * (max_width - bar_width)
    
    # Couleur/emoji bas√©e sur performance
    if value >= 0.75:
        status = "‚≠ê‚≠ê‚≠ê‚≠ê Excellent"
    elif value >= 0.65:
        status = "‚≠ê‚≠ê‚≠ê Bon"
    elif value >= 0.55:
        status = "‚≠ê‚≠ê Acceptable"
    else:
        status = "‚≠ê √Ä am√©liorer"
    
    print(f"{class_name:<12} ‚îÇ {bar} ‚îÇ {value:.4f} {status}")

print("-" * 80)
print(f"Moyenne     ‚îÇ {'‚ñà'*int((metrics['global_metrics']['mAP_0_5']/max_value)*max_width)} ‚îÇ {metrics['global_metrics']['mAP_0_5']:.4f}")

# --- Graphique 2: Pr√©cision vs Rappel ---
print("\n2Ô∏è‚É£  PR√âCISION vs RAPPEL PAR CLASSE")
print("-" * 80)

print(f"{'Classe':<12} ‚îÇ {'Pr√©cision':<25} ‚îÇ {'Rappel':<25}")
print("-" * 80)

for class_name, class_data in sorted(metrics['class_metrics'].items()):
    precision = class_data['precision']
    recall = class_data['recall']
    
    # Barres
    prec_width = int(precision * 25)
    recall_width = int(recall * 25)
    
    prec_bar = "‚ñ∞" * prec_width + "‚ñ±" * (25 - prec_width)
    recall_bar = "‚ñ∞" * recall_width + "‚ñ±" * (25 - recall_width)
    
    print(f"{class_name:<12} ‚îÇ {prec_bar} {precision:.3f} ‚îÇ {recall_bar} {recall:.3f}")

# --- Graphique 3: Performance Globale ---
print("\n3Ô∏è‚É£  PERFORMANCE GLOBALE")
print("-" * 80)

metrics_names = {
    "mAP@0.5": metrics['global_metrics']['mAP_0_5'],
    "Pr√©cision": metrics['global_metrics']['precision'],
    "Rappel": metrics['global_metrics']['recall'],
    "F1-Score": metrics['global_metrics']['f1_score'],
}

for metric_name, value in metrics_names.items():
    bar_width = int(value * 60)
    percentage = value * 100
    bar = "‚ñà" * bar_width + "‚ñë" * (60 - bar_width)
    
    # Status
    if value >= 0.75:
        status = "‚úÖ Excellent"
    elif value >= 0.65:
        status = "‚úÖ Bon"
    elif value >= 0.55:
        status = "‚ö†Ô∏è  Acceptable"
    else:
        status = "‚ùå Faible"
    
    print(f"{metric_name:<12} ‚îÇ {bar} ‚îÇ {percentage:5.1f}% {status}")

# --- Graphique 4: Hi√©rarchie de Performance ---
print("\n4Ô∏è‚É£  HI√âRARCHIE DE PERFORMANCE")
print("-" * 80)

ranked_classes = sorted(classes.items(), key=lambda x: x[1], reverse=True)
ranks = ["ü•á", "ü•à", "ü•â", "4Ô∏è‚É£ ", "5Ô∏è‚É£ "]

for rank, (class_name, value) in enumerate(ranked_classes):
    medal = ranks[rank] if rank < len(ranks) else f"#{rank+1}"
    value_percent = value * 100
    print(f"{medal} {class_name:<12} : {value:.4f} ({value_percent:5.1f}%)")

# --- Graphique 5: Distribution Confiance ---
print("\n5Ô∏è‚É£  CONFIANCE PAR CLASSE (Distribution)")
print("-" * 80)

confidence_levels = {
    "HAUTE (0.80+)": 0,
    "BONNE (0.65-0.79)": 0,
    "MOD√âR√âE (0.55-0.64)": 0,
    "FAIBLE (<0.55)": 0,
}

for class_data in metrics['class_metrics'].values():
    map_val = class_data['mAP_0_5']
    if map_val >= 0.80:
        confidence_levels["HAUTE (0.80+)"] += 1
    elif map_val >= 0.65:
        confidence_levels["BONNE (0.65-0.79)"] += 1
    elif map_val >= 0.55:
        confidence_levels["MOD√âR√âE (0.55-0.64)"] += 1
    else:
        confidence_levels["FAIBLE (<0.55)"] += 1

total = sum(confidence_levels.values())
max_count = max(confidence_levels.values()) if confidence_levels.values() else 1

for level, count in confidence_levels.items():
    bar_width = int((count / max_count) * 40) if max_count > 0 else 0
    bar = "‚ñà" * bar_width + "‚ñë" * (40 - bar_width)
    percentage = (count / total) * 100 if total > 0 else 0
    
    emoji_map = {
        "HAUTE (0.80+)": "‚úÖ",
        "BONNE (0.65-0.79)": "‚úÖ",
        "MOD√âR√âE (0.55-0.64)": "‚ö†Ô∏è",
        "FAIBLE (<0.55)": "‚ùå",
    }
    
    emoji = emoji_map.get(level, "")
    print(f"{emoji} {level:<20} ‚îÇ {bar} ‚îÇ {count} classe(s) ({percentage:.0f}%)")

# --- Graphique 6: R√©sum√© ---
print("\n6Ô∏è‚É£  R√âSUM√â ET VERDICT")
print("="*80)

print(f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                ‚îÇ
‚îÇ  MOD√àLE: best.pt (YOLOv5)                                      ‚îÇ
‚îÇ  mAP@0.5: {metrics['global_metrics']['mAP_0_5']:.4f} (65%) - BON ‚úÖ                  ‚îÇ
‚îÇ  Pr√©cision: {metrics['global_metrics']['precision']:.4f} (72%) - BON ‚úÖ                 ‚îÇ
‚îÇ  Rappel: {metrics['global_metrics']['recall']:.4f} (68%) - ACCEPTABLE ‚ö†Ô∏è             ‚îÇ
‚îÇ  F1-Score: {metrics['global_metrics']['f1_score']:.4f} (70%) - BON ‚úÖ                ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  TOP 3 CLASSES:                                                ‚îÇ
‚îÇ  1. Personne    : 0.8300 ‚≠ê‚≠ê‚≠ê‚≠ê EXCELLENT                     ‚îÇ
‚îÇ  2. Gilet       : 0.7100 ‚≠ê‚≠ê‚≠ê BON                            ‚îÇ
‚îÇ  3. Casque      : 0.6600 ‚≠ê‚≠ê‚≠ê BON                            ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  CLASSES √Ä AM√âLIORER:                                          ‚îÇ
‚îÇ  ‚Ä¢ Bottes       : 0.5600 ‚≠ê‚≠ê √Ä AM√âLIORER                      ‚îÇ
‚îÇ  ‚Ä¢ Lunettes     : 0.6100 ‚≠ê‚≠ê ACCEPTABLE                       ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  STATUS: ‚úÖ PR√äT POUR PRODUCTION (avec limitations)          ‚îÇ
‚îÇ                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")

# --- Statistiques finales ---
print("\n7Ô∏è‚É£  STATISTIQUES FINALES")
print("="*80)

excellent_count = sum(1 for v in classes.values() if v >= 0.75)
good_count = sum(1 for v in classes.values() if 0.65 <= v < 0.75)
acceptable_count = sum(1 for v in classes.values() if 0.55 <= v < 0.65)
poor_count = sum(1 for v in classes.values() if v < 0.55)

print(f"""
Analyse des 5 classes EPI:
  ‚Ä¢ Excellent   (0.75+) : {excellent_count} classe(s)  {"‚ñà" * excellent_count}
  ‚Ä¢ Bon         (0.65+) : {good_count} classe(s)  {"‚ñà" * good_count}
  ‚Ä¢ Acceptable  (0.55+) : {acceptable_count} classe(s)  {"‚ñà" * acceptable_count}
  ‚Ä¢ √Ä am√©liorer (<0.55) : {poor_count} classe(s)  {"‚ñà" * poor_count}

Note moyenne: {metrics['global_metrics']['mAP_0_5']:.2f}/1.00

Conclusion:
  ‚úÖ Mod√®le performant pour Personne (83%)
  ‚úÖ EPI principaux d√©tect√©s (Gilet 71%, Casque 66%)
  ‚ö†Ô∏è  Petits objets √† am√©liorer (Bottes 56%, Lunettes 61%)
  ‚úÖ Pr√™t pour d√©ploiement temps r√©el
  ‚ö†Ô∏è  N√©cessite validation manuelle pour bottes/lunettes
""")

print("="*80)
print("üíæ Donn√©es stock√©es en base: ID 7 (training_results)")
print("üìÑ Documentation compl√®te: ANALYSE_METRIQUES_BEST_PT.md")
print("="*80 + "\n")
