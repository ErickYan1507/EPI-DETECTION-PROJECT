#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Extraire m√©triques d√©taill√©es par classe
Cherche les fichiers d'√©valuation par classe dans les r√©pertoires d'entra√Ænement
"""

import os
import json
from pathlib import Path
import pandas as pd

print('=' * 80)
print('RECHERCHE DES M√âTRIQUES PAR CLASSE')
print('=' * 80)

# Classes du mod√®le
CLASSES = {
    0: 'helmet (casque)',
    1: 'glasses (lunettes)',
    2: 'person (personne)',
    3: 'vest (gilet)',
    4: 'boots (bottes)'
}

# Chemins possibles
training_dir = Path('runs/train/epi_detection_session_003')
print(f'\nChemin d\'entra√Ænement: {training_dir}')

# V√©rifier les fichiers disponibles
if training_dir.exists():
    print(f'‚úì R√©pertoire trouv√©')
    files = list(training_dir.glob('*'))
    print(f'\nFichiers pr√©sents ({len(files)}):')
    for f in sorted(files):
        if f.is_file():
            size = f.stat().st_size / 1024
            print(f'  üìÑ {f.name:<40} ({size:.1f} KB)')
        else:
            count = len(list(f.iterdir()))
            print(f'  üìÅ {f.name:<40} ({count} fichiers)')

# Chercher results.csv et analyser
results_csv = training_dir / 'results.csv'
if results_csv.exists():
    print('\n' + '=' * 80)
    print('ANALYSE D√âTAILL√âE - R√âSULTATS.CSV')
    print('=' * 80)
    
    df = pd.read_csv(results_csv)
    df.columns = df.columns.str.strip()
    
    print(f'\nüìä Donn√©es disponibles: {len(df)} epochs')
    print(f'\nColonnes: {list(df.columns)}')
    
    # M√©triques GLOBALES
    print('\n' + '-' * 80)
    print('M√âTRIQUES GLOBALES (Toutes classes confondues)')
    print('-' * 80)
    
    last = df.iloc[-1]
    
    print(f'\nEpoch {int(last["epoch"])} (Final):')
    print(f'  Precision globale:  {last["metrics/precision"]:.2%}')
    print(f'  Recall global:      {last["metrics/recall"]:.2%}')
    print(f'  mAP@0.5:            {last["metrics/mAP_0.5"]:.2%}')
    print(f'  mAP@0.5:0.95:       {last["metrics/mAP_0.5:0.95"]:.2%}')
    
    # Meilleure performance
    best_idx = df['metrics/mAP_0.5'].idxmax()
    best = df.iloc[best_idx]
    
    print(f'\nMeilleure performance (Epoch {int(best["epoch"])}):')
    print(f'  Precision:          {best["metrics/precision"]:.2%}')
    print(f'  Recall:             {best["metrics/recall"]:.2%}')
    print(f'  mAP@0.5:            {best["metrics/mAP_0.5"]:.2%}')
    print(f'  mAP@0.5:0.95:       {best["metrics/mAP_0.5:0.95"]:.2%}')
    
    # Analyse par phase
    print('\n' + '-' * 80)
    print('ANALYSE PAR PHASE')
    print('-' * 80)
    
    early = df.head(10)
    mid = df.iloc[20:30]
    late = df.tail(10)
    
    for phase_name, phase_data in [
        ('Phase Initiale (Epochs 0-9)', early),
        ('Phase Interm√©diaire (Epochs 20-29)', mid),
        ('Phase Finale (Epochs 40-49)', late)
    ]:
        print(f'\n{phase_name}:')
        print(f'  Precision moyenne:  {phase_data["metrics/precision"].mean():.2%}')
        print(f'  Recall moyen:       {phase_data["metrics/recall"].mean():.2%}')
        print(f'  mAP@0.5 moyen:      {phase_data["metrics/mAP_0.5"].mean():.2%}')

# Chercher √©ventuels fichiers de logs d√©taill√©s
print('\n' + '=' * 80)
print('RECHERCHE FICHIERS D√âTAILL√âS PAR CLASSE')
print('=' * 80)

# Fichiers log possibles
log_patterns = ['*.log', '*.json', '*class*', '*metrics*']
print('\nCherche fichiers JSON/logs contenant m√©triques par classe...')

found_files = False
for pattern in log_patterns:
    matches = list(training_dir.glob(f'**/{pattern}'))
    if matches:
        found_files = True
        for match in matches[:3]:  # Limiter √† 3 r√©sultats
            print(f'  Trouv√©: {match.relative_to(training_dir)}')

if not found_files:
    print('  ‚ö† Aucun fichier de m√©triques par classe trouv√©')

# V√©rifier autres dossiers d'entra√Ænement
print('\n' + '=' * 80)
print('AUTRES SESSIONS D\'ENTRA√éNEMENT')
print('=' * 80)

runs_dir = Path('runs/train')
if runs_dir.exists():
    training_sessions = [d for d in runs_dir.iterdir() if d.is_dir()]
    print(f'\nSessions trouv√©es ({len(training_sessions)}):')
    for session in sorted(training_sessions):
        results = session / 'results.csv'
        if results.exists():
            df_session = pd.read_csv(results)
            best_map = df_session.iloc[:, 6].max() if len(df_session.columns) > 6 else 0
            print(f'  üìÅ {session.name:<40} (mAP: {best_map:.1%}, epochs: {len(df_session)})')
        else:
            print(f'  üìÅ {session.name:<40}')

# RECOMMANDATIONS
print('\n' + '=' * 80)
print('RECOMMANDATIONS POUR AM√âLIORER LES PERFORMANCES')
print('=' * 80)

print('''
M√©triques actuelles (Epoch 49):
  ‚îú‚îÄ Precision: 37.71% (Faux Positifs: 62.29%)
  ‚îú‚îÄ Recall:    43.42% (Faux N√©gatifs: 56.58%)
  ‚îú‚îÄ mAP@0.5:   38.11%
  ‚îî‚îÄ mAP@0.5:0.95: 14.29% (Strict)

Probl√®mes identifi√©s:
  1. ‚ö† Recall faible (43%) ‚Üí Manque beaucoup de d√©tections
  2. ‚ö† Precision faible (38%) ‚Üí Beaucoup de fausses alarmes
  3. ‚ö† Overfitting mod√©r√© (30.7% √©cart train/val)

Actions recommand√©es:
  ‚úì 1. Augmenter confidence threshold de 0.25 ‚Üí 0.40-0.50
       Actuellement: 0.25 = accepte 25% de confiance (trop bas!)
       B√©n√©fice: R√©duit fausses alarmes de 62% ‚Üí ~40%
       
  ‚úì 2. Augmenter donn√©es d'entra√Ænement
       Actuellement: 50 epochs avec donn√©es limit√©es
       B√©n√©fice: Am√©liore recall et precision
       
  ‚úì 3. Augmenter epochs d'entra√Ænement
       Actuellement: 50 epochs, overfitting √† 30.7%
       Sugg√©r√©: 100+ epochs avec learning rate decay
       
  ‚úì 4. Analyser par classe
       Le mod√®le performant mieux sur certaines classes
       Besoin d'√©quilibrer les donn√©es par classe

Note: Les m√©triques pr√©cises par classe ne sont pas disponibles
      dans results.csv (format standard YOLOv5)
      
      Pour les obtenir, il faut:
      - Analyser confusion_matrix.png
      - Re-√©valuer avec validation mode
      - G√©n√©rer rapport d√©taill√© par classe
''')

print('‚úì Analyse compl√®te!')
