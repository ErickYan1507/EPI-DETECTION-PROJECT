"""
Script d'optimisation pour accÃ©lÃ©rer l'entraÃ®nement YOLOv5
Configure tous les paramÃ¨tres pour maximiser la vitesse d'entraÃ®nement
"""

import os
import torch
from pathlib import Path

def optimize_training_speed():
    """Optimise tous les paramÃ¨tres pour la vitesse d'entraÃ®nement maximale"""

    print("ğŸš€ OPTIMISATION DE LA VITESSE D'ENTRAÃNEMENT")
    print("=" * 60)

    # 1. VÃ©rifier le matÃ©riel disponible
    print("\n1. ğŸ“Š ANALYSE DU MATÃ‰RIEL")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   Device: {device}")

    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   CUDA: {torch.version.cuda}")
        print(f"   MÃ©moire GPU: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB")
        gpu_memory = torch.cuda.get_device_properties(0).total_memory // 1024**3
    else:
        print("   âš ï¸  Aucun GPU dÃ©tectÃ© - l'entraÃ®nement sera lent")
        gpu_memory = 0

    # 2. Optimisations de configuration
    print("\n2. âš™ï¸  CONFIGURATIONS OPTIMISÃ‰ES")

    # Calculer la taille de batch optimale
    if gpu_memory >= 8:  # 8GB+ GPU
        batch_size = 32
        img_size = 640
    elif gpu_memory >= 4:  # 4-8GB GPU
        batch_size = 16
        img_size = 640
    else:  # CPU ou petit GPU
        batch_size = 8
        img_size = 416

    print(f"   Batch size recommandÃ©: {batch_size}")
    print(f"   Taille d'image: {img_size}x{img_size}")
    print("   PrÃ©cision: FP16 activÃ©e")
    print("   Workers DataLoader: 8")
    print("   Cache images: ActivÃ©")
    print("   Freeze backbone: ActivÃ© (couches 0-9)")
    print("   Sauvegarde checkpoints: Tous les 10 epochs")

    # 3. CrÃ©er le fichier d'optimisation pour YOLOv5
    create_optimized_train_script(batch_size, img_size)

    # 4. Recommandations supplÃ©mentaires
    print("\n3. ğŸ’¡ RECOMMANDATIONS SUPPLÃ‰MENTAIRES")
    print("   â€¢ Utilisez --cache ram si vous avez assez de RAM")
    print("   â€¢ DÃ©sactivez les augmentations lourdes si possible")
    print("   â€¢ Utilisez --rect pour des batches rectangulaires")
    print("   â€¢ ConsidÃ©rez --evolve pour optimiser les hyperparamÃ¨tres")

    print("\n4. ğŸƒâ€â™‚ï¸ SCRIPT D'ENTRAÃNEMENT OPTIMISÃ‰ CRÃ‰Ã‰")
    print("   ExÃ©cutez: python train_ultra_fast.py")

def create_optimized_train_script(batch_size, img_size):
    """CrÃ©e un script d'entraÃ®nement ultra-optimisÃ©"""

    script_content = f'''"""
Script d'entraÃ®nement YOLOv5 ultra-optimisÃ© pour la vitesse maximale
"""

import torch
import os
from pathlib import Path

def main():
    # Configuration optimisÃ©e pour la vitesse
    batch_size = {batch_size}
    img_size = {img_size}
    epochs = 100

    # Commande d'entraÃ®nement optimisÃ©e
    cmd = f"""
    python train.py \\
        --img {{img_size}} \\
        --batch {{batch_size}} \\
        --epochs {{epochs}} \\
        --data data/epi_data.yaml \\
        --weights yolov5s.pt \\
        --cache ram \\
        --device 0 \\
        --workers 8 \\
        --project runs/train \\
        --name epi_ultra_fast \\
        --hyp data/hyps/hyp.scratch-low.yaml \\
        --optimizer AdamW \\
        --freeze 10 \\
        --save-period 10 \\
        --patience 50 \\
        --rect
    """

    print("ğŸš€ LANCEMENT ENTRAÃNEMENT ULTRA-RAPIDE")
    print(f"   Batch size: {{batch_size}}")
    print(f"   Image size: {{img_size}}x{{img_size}}")
    print(f"   Epochs: {{epochs}}")
    print("   Cache: RAM activÃ©")
    print("   Workers: 8")
    print("   Freeze: 10 couches")
    print("   Rect: ActivÃ©")
    print()
    print("Commande Ã  exÃ©cuter:")
    print(cmd)

    # VÃ©rifier GPU
    if torch.cuda.is_available():
        print(f"âœ… GPU dÃ©tectÃ©: {{torch.cuda.get_device_name(0)}}")
        print(f"   MÃ©moire: {{torch.cuda.get_device_properties(0).total_memory // 1024**3}} GB")
    else:
        print("âš ï¸  Aucun GPU - entraÃ®nement sur CPU (sera lent)")

    print("\\n" + "="*60)
    print("ğŸ’¡ ASTUCES DE PERFORMANCE:")
    print("   â€¢ Fermez autres applications utilisant le GPU")
    print("   â€¢ Surveillez l'utilisation GPU avec nvidia-smi")
    print("   â€¢ Si OOM: rÃ©duisez batch_size ou img_size")
    print("="*60)

if __name__ == "__main__":
    main()
'''

    with open('train_ultra_fast.py', 'w', encoding='utf-8') as f:
        f.write(script_content)

    print("   âœ… Script train_ultra_fast.py crÃ©Ã©")

def create_ultra_fast_config():
    """CrÃ©e une configuration ultra-optimisÃ©e"""

    config_content = '''# Configuration ultra-optimisÃ©e pour vitesse maximale

# Dataset
train: dataset/images/train
val: dataset/images/val
test: dataset/images/test

# Classes
nc: 5
names: ['helmet', 'glasses', 'person', 'vest', 'boots']

# Optimisations de vitesse
cache: ram  # Cache en RAM pour vitesse maximale
'''

    # CrÃ©er le dossier data s'il n'existe pas
    os.makedirs('data', exist_ok=True)

    with open('data/epi_ultra_fast.yaml', 'w', encoding='utf-8') as f:
        f.write(config_content)

    print("   âœ… Configuration epi_ultra_fast.yaml crÃ©Ã©e")

if __name__ == "__main__":
    optimize_training_speed()
    create_ultra_fast_config()
    yaml_path.write_text(content)
    print(f"âœ… data.yaml mis Ã  jour")

def print_optimization_guide():
    """Afficher les paramÃ¨tres optimisÃ©s recommandÃ©s"""
    print("\n" + "="*70)
    print("âš¡ PARAMÃˆTRES D'ENTRAÃNEMENT OPTIMISÃ‰S")
    print("="*70)
    print("""
ğŸ“Š COMPARAISON: Avant vs AprÃ¨s
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ParamÃ¨tre       â”‚ Avant    â”‚ AprÃ¨s     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Image size      â”‚ 640Ã—640  â”‚ 416Ã—416   â”‚ -57% images
â”‚ Batch size      â”‚ 8-16     â”‚ 32-48     â”‚ Mieux GPU util
â”‚ Workers         â”‚ 8        â”‚ 12-16     â”‚ Chargement + rapide
â”‚ Cache           â”‚ disk     â”‚ ram       â”‚ Lecture directe
â”‚ Epochs/epoch    â”‚ 1554     â”‚ ~600      â”‚ -62% itÃ©rations
â”‚ Temps/epoch     â”‚ 3:00h    â”‚ 20-30min  â”‚ -85% gain
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ COMMANDE OPTIMISÃ‰E:
python train.py \\
    --epochs 50 \\
    --batch-size 48 \\
    --img 416 \\
    --optimizer Adam \\
    --workers 16 \\
    --cache ram \\
    --rect \\
    --quad \\
    --cos-lr \\
    --patience 10 \\
    --label-smoothing 0.1

âš ï¸  NOTES IMPORTANTES:
1. RÃ©duire resolution: 640 â†’ 416 = -62% itÃ©rations/epoch
2. Augmenter batch: 8-16 â†’ 32-48 = 2-3x plus rapide
3. Cache RAM: 5-10x plus rapide que disk
4. Patience rÃ©duite: 30 â†’ 10 (early stopping)
5. AprÃ¨s optimization: relancer avec resolution 640 si prÃ©cision insuffisante
""")

def create_optimized_train_script():
    """CrÃ©er un script d'entraÃ®nement optimisÃ©"""
    script_content = '''#!/usr/bin/env python3
"""EntraÃ®nement YOLOv5 OPTIMISÃ‰ pour vitesse maximale"""

import subprocess
import sys
import torch

def main():
    # ParamÃ¨tres optimisÃ©s
    params = {
        'epochs': 50,
        'batch_size': 48,
        'img_size': 416,
        'weights': 'yolov5s.pt',
        'device': 'cuda:0' if torch.cuda.is_available() else 'cpu',
    }
    
    device = params['device']
    if device != 'cpu':
        # VÃ©rifier VRAM disponible
        props = torch.cuda.get_device_properties(0)
        total_memory = props.total_memory / 1e9
        print(f"âœ… GPU trouvÃ©: {props.name} ({total_memory:.1f}GB VRAM)")
        
        # Ajuster batch size selon VRAM
        if total_memory < 4:
            params['batch_size'] = 16
            print(f"âš ï¸  VRAM limitÃ©e, batch_size rÃ©duit Ã  {params['batch_size']}")
        elif total_memory < 8:
            params['batch_size'] = 32
    
    cmd = [
        sys.executable, 'yolov5/train.py',
        '--weights', params['weights'],
        '--data', 'dataset/data.yaml',
        '--epochs', str(params['epochs']),
        '--batch-size', str(params['batch_size']),
        '--img', str(params['img_size']),
        '--device', device,
        '--project', 'runs/train',
        '--name', 'optimized_training',
        '--exist-ok',
        # OPTIMISATIONS CRITIQUES
        '--optimizer', 'Adam',
        '--rect',
        '--quad',
        '--cos-lr',
        '--cache', 'ram',  # CRUCIAL: mettre en RAM si possible
        '--workers', '16',
        '--patience', '10',
        '--label-smoothing', '0.1',
        '--save-period', '10',  # Sauvegarder tous les 10 epochs
    ]
    
    print(f"\\nğŸš€ Lancement avec: {' '.join(cmd[2:])}\\n")
    subprocess.run(cmd)

if __name__ == '__main__':
    main()
'''
    
    script_path = Path('quick_train_optimized.py')
    script_path.write_text(script_content)
    script_path.chmod(0o755)
    print(f"âœ… Script crÃ©Ã©: {script_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Optimisation agressive du temps d\'entraÃ®nement')
    parser.add_argument('--resize', action='store_true', help='Redimensionner le dataset')
    parser.add_argument('--size', type=int, default=416, help='Taille cible (default: 416)')
    parser.add_argument('--dataset', default='dataset', help='Chemin du dataset')
    parser.add_argument('--guide', action='store_true', help='Afficher le guide d\'optimisation')
    parser.add_argument('--create-script', action='store_true', help='CrÃ©er script d\'entraÃ®nement optimisÃ©')
    
    args = parser.parse_args()
    
    if args.guide or (not args.resize and not args.create_script):
        print_optimization_guide()
    
    if args.resize:
        resize_dataset(args.dataset, args.size)
        adjust_yaml_resolution(args.dataset + '/data.yaml', args.size)
    
    if args.create_script:
        create_optimized_train_script()
